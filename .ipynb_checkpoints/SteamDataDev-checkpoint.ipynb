{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "current_year = dt.today().year\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.2 Safari/605.1.15'}\n",
    "\n",
    "def get_review_count(id):\n",
    "    \"\"\"Return total number of reviews of default language.\n",
    "\n",
    "    Args:\n",
    "        id (int or str): Game id.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of reviews.\n",
    "    \"\"\"    \n",
    "\n",
    "    url = 'https://store.steampowered.com/app/' + str(id)\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    count = soup.find('label', {'for': 'review_language_mine'}).span.text\n",
    "    count = count.strip('()').replace(',','')\n",
    "    return int(count)\n",
    "\n",
    "\n",
    "def search_game_id(search_term, all_results=False): \n",
    "    \"\"\"Return Dataframe of game ids of the search term from Steam's search result page.\n",
    "\n",
    "    Args:\n",
    "        search_term (str): Game name to search.\n",
    "        all_results (bool, optional): Whether to return all games results of the search term or the top one result. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Dataframe with two columns \"game\" and \"id\".\n",
    "    \"\"\"    \n",
    "    page = 1\n",
    "    game = []\n",
    "    id = []\n",
    "    if not all_results:\n",
    "        url = f'https://store.steampowered.com/search/?category1=998&page={page}&term={search_term}'\n",
    "        html = requests.get(url, headers=headers).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        search_results = soup.find(class_='search_result_row')\n",
    "        game = search_results.find('span', class_='title').text\n",
    "        id = search_results['data-ds-appid']\n",
    "        return pd.DataFrame({\n",
    "            'game':[game],\n",
    "            'id':[id]\n",
    "        })\n",
    "    else:\n",
    "        while True:\n",
    "            url = f'https://store.steampowered.com/search/?category1=998&page={page}&term={search_term}'\n",
    "            html = requests.get(url, headers=headers).text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            search_results = soup.find_all(class_='search_result_row')\n",
    "            if not search_results:\n",
    "                break\n",
    "            \n",
    "            title = [result.find('span', class_='title').text for result in search_results]\n",
    "            appid = [result['data-ds-appid'] for result in search_results]\n",
    "            game.extend(title)\n",
    "            id.extend(appid)\n",
    "            page += 1\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'game':game,\n",
    "            'id':id\n",
    "        })\n",
    "\n",
    "\n",
    "def get_game_ids(n, filter='topsellers'):\n",
    "    \"\"\"Return Dataframe of n games' ids from Steam's search result page.\n",
    "\n",
    "    Args:\n",
    "        n (int): number of games to collect.\n",
    "        filter (str, optional): filter for search results. Defaults to 'topsellers'.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Dataframe with two columns \"game\" and \"id\".\n",
    "    \"\"\"    \n",
    "    page = 1\n",
    "    game = []\n",
    "    id = []\n",
    "    while len(game) < n:\n",
    "        url = f'https://store.steampowered.com/search/?category1=998&page={page}&filter={filter}'\n",
    "        html = requests.get(url, headers=headers).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        search_results = soup.find_all(class_='search_result_row')\n",
    "        if not search_results:\n",
    "            break\n",
    "        \n",
    "        title = [result.find('span', class_='title').text for result in search_results]\n",
    "        appid = [result['data-ds-appid'] for result in search_results]\n",
    "        game.extend(title)\n",
    "        id.extend(appid)\n",
    "        page += 1\n",
    "    num = min(n, len(game))\n",
    "    return pd.DataFrame({\n",
    "        'game':game[:num],\n",
    "        'id':id[:num]\n",
    "    })\n",
    "\n",
    "def clean_date(date):\n",
    "    \"\"\"Helper function to clean review date pulled from Steam's review page for a game.\n",
    "\n",
    "    Strip 'Posted: ' from the date string.\n",
    "    Add current year to date if review was posted in the current year.\n",
    "\n",
    "        Typical usage example:\n",
    "        >>> clean_date('Posted: May 6')\n",
    "        'May 6, 2021'\n",
    "\n",
    "    Args:\n",
    "        date (str): Date string pulled from review page.\n",
    "\n",
    "    Returns:\n",
    "        str: Clean date string.\n",
    "    \"\"\"    \n",
    "    date = date.split(' ',1)[1]\n",
    "    try: \n",
    "        dt.strptime(date,'%B %d, %Y')\n",
    "        pass\n",
    "    except ValueError:\n",
    "        date += ', ' +str(current_year)\n",
    "    return date\n",
    "\n",
    "\n",
    "def get_game_review(id, language='default'):\n",
    "    \"\"\"Collect all review for a given game.\n",
    "\n",
    "    Typical usage example:\n",
    "\n",
    "    English reviews for Counter-Strike: Global Offensive.\n",
    "    Game id can be found using search_game_id(\"Counter-Strike: Global Offensive\")\n",
    "    or from game's Steam page url.\n",
    "    >>> reviews = get_game_review(730, language='english')\n",
    "\n",
    "    Args:\n",
    "        id (int or str): Game id \n",
    "        language (str, optional): The language in which to get the reviews. Defaults to 'default', \n",
    "            which is the default language of your Steam account.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Dataframe for reviews with the following columns:\n",
    "\n",
    "        | name                | description                                           | dtype   |\n",
    "        |---------------------|-------------------------------------------------------|---------|\n",
    "        | user                | user name of the review                               | object  |\n",
    "        | playtime            | total playtime (in hours) the user spent on this game | float64 |\n",
    "        | user_link           | user's profile page url                               | object  |\n",
    "        | post_date           | review's post date                                    | object  |\n",
    "        | helpfulness         | number of people found this review helpful            | int64   |\n",
    "        | review              | review content                                        | object  |\n",
    "        | recommend           | whether the user recommend the game                   | object  |\n",
    "        | early_access_review | whether this is an early access review                | object  |\n",
    "            \"\"\"    \n",
    "    user_name_list = []\n",
    "    hour_list = []\n",
    "    user_link_list = []\n",
    "    post_date_list = []\n",
    "    helpful_list = []\n",
    "    comment_list = []\n",
    "    title_list = []\n",
    "    early_access_list = []\n",
    "\n",
    "    cursor = ''\n",
    "    i=0\n",
    "    while True:\n",
    "        url=f'https://steamcommunity.com/app/{id}/homecontent/'\n",
    "        params = {\n",
    "            'userreviewsoffset': i  * 10,\n",
    "            'p': i + 1,\n",
    "            'workshopitemspage': i + 1,\n",
    "            'readytouseitemspage': i + 1,\n",
    "            'mtxitemspage': i + 1,\n",
    "            'itemspage': i + 1,\n",
    "            'screenshotspage': i + 1,\n",
    "            'videospage': i + 1,\n",
    "            'artpage': i + 1,\n",
    "            'allguidepage': i + 1,\n",
    "            'webguidepage': i + 1,\n",
    "            'integeratedguidepage': i + 1,\n",
    "            'discussionspage': i + 1,\n",
    "            'numperpage': 10,\n",
    "            'browsefilter': 'toprated',\n",
    "            'browsefilter': 'toprated',\n",
    "            'appid': id,\n",
    "            'appHubSubSection': 10,\n",
    "            'l': 'english',\n",
    "            'filterLanguage': language,\n",
    "            'searchText': '',\n",
    "            'forceanon':1,\n",
    "            'maxInappropriateScore':50,\n",
    "        }\n",
    "        if i > 0:\n",
    "            params['userreviewscursor'] = cursor\n",
    "        html = requests.get(url, headers=headers, params=params).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        reviews=soup.find_all('div', {'class': 'apphub_Card'})\n",
    "        \n",
    "        if not reviews:\n",
    "            break\n",
    "            \n",
    "        users = [review.find('div', {'class': 'apphub_CardContentAuthorName'}) for review in reviews]\n",
    "        user_name = [user.find('a').text for user in users]\n",
    "        user_link = [user.find('a').attrs['href'] for user in users]\n",
    "        title = [review.find('div', {'class': 'title'}).text for review in reviews]\n",
    "        hour = [float(review.find('div', {'class': 'hours'}).text.split(' ')[0]) if review.find('div', {'class': 'hours'}) \n",
    "                else np.nan for review in reviews]\n",
    "        helpful = [review.find('div',{'class': 'found_helpful'}).get_text(strip=True).split(' ')[0] for review in reviews]\n",
    "        helpful = [0 if num == 'No' else int(num) for num in helpful]\n",
    "        comment_section = [review.find('div', {'class': 'apphub_CardTextContent'}) for review in reviews]\n",
    "        raw_post_date = [x.find('div',{'class':'date_posted'}).get_text(strip=True) for x in comment_section]\n",
    "        post_date = [clean_date(date) for date in raw_post_date]\n",
    "        comment = [''.join(review.find_all(text=True, recursive=False)).strip() for review in comment_section]\n",
    "        early_access = [x.find('div',{'class': 'early_access_review'}).text if x.find('div',{'class': 'early_access_review'}) \n",
    "                        else None for x in comment_section]\n",
    "        # A response includes a ‘userreviewscursor’ attribute, marking which review your request completed on. \n",
    "        # Adding same cursor in the next request’s parameters to get the next 10 reviews. \n",
    "        # Otherwise it will return the same 10 reivews as last request.\n",
    "        cursor = soup.find_all('form')[0].find('input',{'name': 'userreviewscursor'})['value']\n",
    "\n",
    "        user_name_list.extend(user_name)\n",
    "        hour_list.extend(hour)\n",
    "        user_link_list.extend(user_link)\n",
    "        post_date_list.extend(post_date)\n",
    "        helpful_list.extend(helpful)\n",
    "        comment_list.extend(comment)\n",
    "        title_list.extend(title)\n",
    "        early_access_list.extend(early_access)\n",
    "        i += 1\n",
    "\n",
    "    review_df=pd.DataFrame({\n",
    "        'user': user_name_list,\n",
    "        'playtime': hour_list,\n",
    "        'user_url': user_link_list,\n",
    "        'post_date': post_date_list,\n",
    "        'helpfulness': helpful_list,\n",
    "        'review': comment_list,\n",
    "        'recommend': title_list,\n",
    "        'early_access_review': early_access_list\n",
    "    })\n",
    "    return review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
